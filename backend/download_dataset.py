"""
download_dataset.py
1. è¨­å®š Kaggle æ†‘è­‰ï¼ˆå¾ .kaggle/kaggle.json è¤‡è£½è‡³ä½¿ç”¨è€…ç›®éŒ„ï¼‰
2. ä¸‹è¼‰ PlantVillage è³‡æ–™é›†ï¼ˆemmarex/plantdiseaseï¼‰
3. è§£å£“ç¸® ZIP æª”
4. å°‡åœ–ç‰‡åˆ†é¡æ•´ç†è‡³ data/train / data/valï¼ˆ80/20 åˆ‡å‰²ï¼‰
5. åˆªé™¤åŸå§‹å£“ç¸®æª”é‡‹æ”¾ç©ºé–“
"""
import os
import sys
import json
import shutil
import zipfile
import random
import subprocess
from pathlib import Path

# â”€â”€â”€ è·¯å¾‘è¨­å®š â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
BASE_DIR        = Path(__file__).parent
KAGGLE_JSON_SRC = BASE_DIR / ".kaggle" / "kaggle.json"
KAGGLE_JSON_DST = Path.home() / ".kaggle" / "kaggle.json"
DOWNLOAD_DIR    = BASE_DIR / "data" / "raw"
EXTRACT_DIR     = BASE_DIR / "data" / "extracted"
TRAIN_DIR       = BASE_DIR / "data" / "train"
VAL_DIR         = BASE_DIR / "data" / "val"

DATASET_SLUG    = "emmarex/plantdisease"
ZIP_NAME        = "plantdisease.zip"
VAL_SPLIT       = 0.2
RANDOM_SEED     = 42


def setup_kaggle_credentials():
    """è¤‡è£½ kaggle.json åˆ°ä½¿ç”¨è€… home ç›®éŒ„"""
    if not KAGGLE_JSON_SRC.exists():
        print(f"âŒ æ‰¾ä¸åˆ° {KAGGLE_JSON_SRC}")
        print("   è«‹å…ˆç·¨è¼¯ backend/.kaggle/kaggle.jsonï¼Œå¡«å…¥ä½ çš„ Kaggle username å’Œ API key")
        print("   å–å¾—æ–¹å¼ï¼šhttps://www.kaggle.com/ â†’ Settings â†’ API â†’ Create New Token")
        sys.exit(1)

    # æª¢æŸ¥æ˜¯å¦ç‚ºç¯„æœ¬ï¼ˆæœªå¡«å¯«ï¼‰
    with open(KAGGLE_JSON_SRC) as f:
        creds = json.load(f)
    if creds.get("username") == "YOUR_KAGGLE_USERNAME":
        print("âŒ è«‹å…ˆå¡«å¯« backend/.kaggle/kaggle.json ä¸­çš„ username å’Œ keyï¼")
        sys.exit(1)

    KAGGLE_JSON_DST.parent.mkdir(parents=True, exist_ok=True)
    shutil.copy2(KAGGLE_JSON_SRC, KAGGLE_JSON_DST)
    KAGGLE_JSON_DST.chmod(0o600)
    print(f"âœ… Kaggle æ†‘è­‰å·²è¨­å®šï¼š{KAGGLE_JSON_DST}")


def download_dataset():
    """ä½¿ç”¨ Kaggle CLI ä¸‹è¼‰è³‡æ–™é›†"""
    DOWNLOAD_DIR.mkdir(parents=True, exist_ok=True)
    zip_path = DOWNLOAD_DIR / ZIP_NAME

    if zip_path.exists():
        print(f"âš¡ å·²å­˜åœ¨å£“ç¸®æª”ï¼Œè·³éä¸‹è¼‰ï¼š{zip_path}")
        return zip_path

    print(f"ğŸ“¥ ä¸‹è¼‰è³‡æ–™é›†ï¼š{DATASET_SLUG}")
    print(f"   ç›®æ¨™ç›®éŒ„ï¼š{DOWNLOAD_DIR}")
    cmd = [
        sys.executable, "-m", "kaggle",
        "datasets", "download",
        "-d", DATASET_SLUG,
        "-p", str(DOWNLOAD_DIR),
        "--force"
    ]
    result = subprocess.run(cmd, capture_output=True, text=True)
    if result.returncode != 0:
        print(f"âŒ ä¸‹è¼‰å¤±æ•—ï¼š\n{result.stderr}")
        sys.exit(1)

    # Kaggle CLI ä¸‹è¼‰çš„æª”æ¡ˆåç¨±å¯èƒ½ä¸åŒï¼Œå°‹æ‰¾ zip
    zips = list(DOWNLOAD_DIR.glob("*.zip"))
    if not zips:
        print("âŒ æ‰¾ä¸åˆ°ä¸‹è¼‰çš„ ZIP æª”")
        sys.exit(1)
    print(f"âœ… ä¸‹è¼‰å®Œæˆï¼š{zips[0]}")
    return zips[0]


def extract_dataset(zip_path: Path):
    """è§£å£“ç¸®è³‡æ–™é›†"""
    if EXTRACT_DIR.exists() and any(EXTRACT_DIR.iterdir()):
        print(f"âš¡ å·²è§£å£“ç¸®ï¼Œè·³éï¼š{EXTRACT_DIR}")
        return

    EXTRACT_DIR.mkdir(parents=True, exist_ok=True)
    print(f"ğŸ“¦ è§£å£“ç¸®ä¸­ï¼š{zip_path} â†’ {EXTRACT_DIR}")
    with zipfile.ZipFile(zip_path, "r") as zf:
        total = len(zf.namelist())
        for i, member in enumerate(zf.namelist(), 1):
            zf.extract(member, EXTRACT_DIR)
            if i % 5000 == 0:
                print(f"   {i}/{total} æª”æ¡ˆè§£å£“å®Œæˆ...")
    print(f"âœ… è§£å£“ç¸®å®Œæˆï¼Œå…± {total} å€‹æª”æ¡ˆ")


def organize_dataset():
    """
    å°‡è§£å£“ç¸®å¾Œçš„åœ–ç‰‡æ•´ç†è‡³ data/train å’Œ data/val
    åŸå§‹çµæ§‹ï¼šextracted/PlantVillage/<é¡åˆ¥>/<åœ–ç‰‡>
    ç›®æ¨™çµæ§‹ï¼š
      data/train/<é¡åˆ¥>/<åœ–ç‰‡>
      data/val/<é¡åˆ¥>/<åœ–ç‰‡>
    """
    if TRAIN_DIR.exists() and VAL_DIR.exists():
        train_count = sum(1 for _ in TRAIN_DIR.rglob("*.jpg"))
        if train_count > 100:
            print(f"âš¡ è³‡æ–™é›†å·²æ•´ç†ï¼ˆ{train_count} å¼µè¨“ç·´åœ–ï¼‰ï¼Œè·³é")
            return

    # æ‰¾åˆ°é¡åˆ¥è³‡æ–™å¤¾ï¼ˆéè¿´æœå°‹åŒ…å«åœ–ç‰‡çš„è³‡æ–™å¤¾ï¼‰
    source_dirs = []
    for d in EXTRACT_DIR.rglob("*"):
        if d.is_dir():
            imgs = list(d.glob("*.jpg")) + list(d.glob("*.JPG")) + \
                   list(d.glob("*.png")) + list(d.glob("*.PNG")) + \
                   list(d.glob("*.jpeg"))
            if len(imgs) > 10:
                source_dirs.append((d.name, imgs))

    if not source_dirs:
        print("âŒ æ‰¾ä¸åˆ°åœ–ç‰‡è³‡æ–™å¤¾ï¼Œè«‹ç¢ºèªè§£å£“ç¸®æ˜¯å¦æˆåŠŸ")
        return

    print(f"\nğŸ“‚ æ•´ç† {len(source_dirs)} å€‹é¡åˆ¥åˆ° train/val è³‡æ–™å¤¾...")
    random.seed(RANDOM_SEED)

    total_train, total_val = 0, 0
    class_summary = []

    for class_name, imgs in sorted(source_dirs):
        random.shuffle(imgs)
        split_idx = int(len(imgs) * (1 - VAL_SPLIT))
        train_imgs = imgs[:split_idx]
        val_imgs   = imgs[split_idx:]

        # å»ºç«‹ç›®æ¨™è³‡æ–™å¤¾
        (TRAIN_DIR / class_name).mkdir(parents=True, exist_ok=True)
        (VAL_DIR   / class_name).mkdir(parents=True, exist_ok=True)

        # è¤‡è£½ï¼ˆç”¨ hard link ç¯€çœç©ºé–“ï¼Œè‹¥è·¨ç£ç¢Ÿå‰‡ç”¨ copyï¼‰
        for src in train_imgs:
            dst = TRAIN_DIR / class_name / src.name
            if not dst.exists():
                try:
                    os.link(src, dst)
                except OSError:
                    shutil.copy2(src, dst)

        for src in val_imgs:
            dst = VAL_DIR / class_name / src.name
            if not dst.exists():
                try:
                    os.link(src, dst)
                except OSError:
                    shutil.copy2(src, dst)

        total_train += len(train_imgs)
        total_val   += len(val_imgs)
        class_summary.append({
            "class": class_name,
            "train": len(train_imgs),
            "val": len(val_imgs)
        })
        print(f"  âœ“ {class_name:<40} train={len(train_imgs):>5}  val={len(val_imgs):>4}")

    # å„²å­˜é¡åˆ¥æ¸…å–®
    classes = [s["class"] for s in class_summary]
    with open(BASE_DIR / "data" / "class_names.json", "w", encoding="utf-8") as f:
        json.dump({"classes": classes, "num_classes": len(classes)}, f, ensure_ascii=False, indent=2)

    print(f"\nâœ… æ•´ç†å®Œæˆï¼")
    print(f"   è¨“ç·´é›†ï¼š{total_train} å¼µ | é©—è­‰é›†ï¼š{total_val} å¼µ | é¡åˆ¥ï¼š{len(class_summary)} ç¨®")


def cleanup_zip(zip_path: Path):
    """åˆªé™¤åŸå§‹å£“ç¸®æª”"""
    if zip_path.exists():
        size_mb = zip_path.stat().st_size / 1024 / 1024
        zip_path.unlink()
        print(f"ğŸ—‘ï¸  å·²åˆªé™¤å£“ç¸®æª”ï¼ˆé‡‹æ”¾ {size_mb:.0f} MBï¼‰ï¼š{zip_path.name}")


def main():
    print("=" * 60)
    print("ğŸŒ¿ PlantVillage è³‡æ–™é›†ä¸‹è¼‰èˆ‡æ•´ç†å·¥å…·")
    print("=" * 60)

    setup_kaggle_credentials()
    zip_path = download_dataset()
    extract_dataset(zip_path)
    organize_dataset()
    cleanup_zip(zip_path)

    print("\n" + "=" * 60)
    print("âœ… å…¨éƒ¨å®Œæˆï¼è³‡æ–™é›†å·²æ•´ç†è‡³ï¼š")
    print(f"   è¨“ç·´é›†ï¼š{TRAIN_DIR}")
    print(f"   é©—è­‰é›†ï¼š{VAL_DIR}")
    print("   ä¸‹ä¸€æ­¥ï¼šåŸ·è¡Œ python train_model.py é–‹å§‹è¨“ç·´")
    print("=" * 60)


if __name__ == "__main__":
    main()